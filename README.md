
# PMF: Progressively Modality Freezing for Multi-Modal Entity Alignment
**The Offical Code for Our Paperï¼š**[Progressively Modality Freezing for Multi-Modal Entity Alignment](https://arxiv.org/abs/2407.16168)**, ACL2024**.

## ğŸ“°Model Overview

We presented the Progressive Modality Freezing (PMF) model to advance Multi-Modal Entity Alignment. 

By measuring and evaluating the relevance of various modalities, PMF progressively freezes features deemed less critical, thereby facilitating the integration and consistency of multi-modal features. Furthermore, we introduced a unified training objective tailored to foster a harmonious contrast between KGs and modalities. 

Empirical evaluations on 9 sub-datasets affirm the superiority of PMF.

![Model](images/model.png)

## ğŸ› ï¸Install

```bash
>> cd PMF-MMEA
>> pip install -r requirement.txt
```

### details

```
Python (>=3.7 )
Pytorch (>= 1.7.0)
numpy (>= 1.19.2)
easydict (>= 1.10)
unidecode (>= 1.3.7)
tensorboard (>= 2.11.2)
```

## ğŸ“‚Dataset

- We assessed the effectiveness of our proposed method using three publicly available MMEA datasets: **DBP15K, MMKG, Multi-OpenEA**
- Download from [GoogleDrive](https://drive.google.com/file/d/1VIWcc3KDcLcRImeSrF2AyhetBLq_gsnx/view?usp=sharing) (1.26G) and unzip it to make those files **satisfy the following file hierarchy**:

```bash
ROOTs
â”œâ”€â”€ data
â”‚   â””â”€â”€ MMKG
â””â”€â”€ PMF-MMEA
```
MMKG detailsï¼š
```bash
MMKG
â”œâ”€DBP15K
â”‚  â”œâ”€fr_en
â”‚  â”‚      ent_ids_1
â”‚  â”‚      ent_ids_2
â”‚  â”‚      ill_ent_ids
â”‚  â”‚      training_attrs_1
â”‚  â”‚      training_attrs_2
â”‚  â”‚      triples_1
â”‚  â”‚      triples_2
â”‚  â”‚
â”‚  â”œâ”€ja_en
â”‚  â”‚      ent_ids_1
â”‚  â”‚      ent_ids_2
â”‚  â”‚      ill_ent_ids
â”‚  â”‚      training_attrs_1
â”‚  â”‚      training_attrs_2
â”‚  â”‚      triples_1
â”‚  â”‚      triples_2
â”‚  â”‚
â”‚  â”œâ”€translated_ent_name
â”‚  â”‚      dbp_fr_en.json
â”‚  â”‚      dbp_ja_en.json
â”‚  â”‚      dbp_zh_en.json
â”‚  â”‚
â”‚  â””â”€zh_en
â”‚          ent_ids_1
â”‚          ent_ids_2
â”‚          ill_ent_ids
â”‚          training_attrs_1
â”‚          training_attrs_2
â”‚          triples_1
â”‚          triples_2
â”‚
â”œâ”€embedding
â”‚      glove.6B.300d.txt
â”‚
â”œâ”€FBDB15K
â”‚  â””â”€norm
â”‚          ent_ids_1
â”‚          ent_ids_2
â”‚          ill_ent_ids
â”‚          training_attrs_1
â”‚          training_attrs_2
â”‚          triples_1
â”‚          triples_2
â”‚
â”œâ”€FBYG15K
â”‚  â””â”€norm
â”‚          ent_ids_1
â”‚          ent_ids_2
â”‚          ill_ent_ids
â”‚          training_attrs_1
â”‚          training_attrs_2
â”‚          triples_1
â”‚          triples_2
â”‚
â””â”€pkls
        dbpedia_wikidata_15k_dense_GA_id_img_feature_dict.pkl
        dbpedia_wikidata_15k_norm_GA_id_img_feature_dict.pkl
        FBDB15K_id_img_feature_dict.pkl
        FBYG15K_id_img_feature_dict.pkl
        fr_en_GA_id_img_feature_dict.pkl
        ja_en_GA_id_img_feature_dict.pkl
        zh_en_GA_id_img_feature_dict.pkl
```
## â›·ï¸Train

### quick start

```bash
# DBP15K
>> bash run_dbp.sh 
# MMKG
>> bash run_fb.sh
# Multi-OpenEA
>> bash run_oea.sh
```

## ğŸ¥‡Results

Model performance report can be found in the file `PMF-MMEA/results/report.csv`

![results](images/results.png)

## ğŸ“Cite

```
@inproceedings{huang2024progressively,
  title={Progressively Modality Freezing for Multi-Modal Entity Alignment},
  author={Huang, Yani and Zhang, Xuefeng and Zhang, Richong and Chen, Junfan and Kim, Jaein},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3477--3489},
  year={2024}
}
```

## ğŸ«¶**Acknowledgement**
This work was supported by CCSE, School of Computer Science and Engineering, Beihang University, Beijing, China.
Our codes are modified based on [MEAformer](https://github.com/zjukg/MEAformer), and we also appreciate [MCLEA](https://github.com/lzxlin/MCLEA), [MSNEA](https://github.com/liyichen-cly/MSNEA), [EVA](https://github.com/cambridgeltl/eva), [MMEA](https://github.com/liyichen-cly/MMEA) and many other related works for their open-source contributions.